{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test AWS Batch workflow\n",
    "\n",
    "List of interferograms to process:\n",
    "A76 ints:\n",
    "* int_20191231_20180116\n",
    "* int_20191231_20161228\n",
    "* int_20191231_20150114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dinosar library not in base environment uncomment below (run just once)\n",
    "#!pip install --no-cache git+https://github.com/scottyhq/dinosar.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import dinosar\n",
    "import geopandas as gpd\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-23.68699916256815,\n",
       " -21.29081519506481,\n",
       " -68.46349117379683,\n",
       " -65.27091018760244]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfa = gpd.read_file('apmb.geojson')\n",
    "gf = dinosar.archive.asf.load_inventory('query.geojson')\n",
    "snwe = dinosar.archive.asf.ogr2snwe('apmb.geojson')\n",
    "snwe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) identify pairs to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use pandas to get list of interferograms programmatically, for now just list a few:\n",
    "relOrbit=76\n",
    "pairs = ['int-20191231-20180116',\n",
    "         'int-20191231-20161228',\n",
    "         'int-20191231-20150114',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate processing directories and push to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp pairs.txt s3://dinosar/processing/uturuncu/A76/pairs.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an S3 bucket and move the list of pairs to S3\n",
    "bucket = 's3://dinosar/processing/uturuncu/A76'\n",
    "pairsFile = 'pairs.txt'\n",
    "\n",
    "paths = [bucket+'/'+x for x in pairs]\n",
    "with open(pairsFile, 'w') as f:\n",
    "    f.write('\\n'.join(paths))\n",
    "\n",
    "cmd = f'aws s3 cp {pairsFile} {bucket}/{pairsFile}'\n",
    "print(cmd)\n",
    "subprocess.call(cmd, shell=True)  # Uncomment to actually run command    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 's3://dinosar/processing/uturuncu/A76/int-20191231-20180116',\n",
       " 1: 's3://dinosar/processing/uturuncu/A76/int-20191231-20161228',\n",
       " 2: 's3://dinosar/processing/uturuncu/A76/int-20191231-20150114'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pairsFile) as f:\n",
    "    pairs = [line.rstrip() for line in f]\n",
    "    mapping = dict(enumerate(pairs))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prep_topsApp_local -i query.geojson -m 20191231 -p 76 -s 20180116 -t template.yml\n",
      "1 prep_topsApp_local -i query.geojson -m 20191231 -p 76 -s 20161228 -t template.yml\n",
      "2 prep_topsApp_local -i query.geojson -m 20191231 -p 76 -s 20150114 -t template.yml\n"
     ]
    }
   ],
   "source": [
    "script = 'prep_topsApp_local'\n",
    "template = 'template.yml'\n",
    "for i,p in enumerate(pairs):\n",
    "    intname = os.path.basename(p)\n",
    "    junk,master,slave=intname.split('-')\n",
    "    intdir = f'int-{master}-{slave}'\n",
    "    cmd = f'{script} -i query.geojson -m {master} -p {relOrbit} -s {slave} -t {template}'\n",
    "    print(i, cmd)\n",
    "    subprocess.call(cmd, shell=True) # Uncomment to actually run command  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 sync int-20191231-20180116/ s3://dinosar/processing/uturuncu/A76/int-20191231-20180116/\n",
      "aws s3 sync int-20191231-20161228/ s3://dinosar/processing/uturuncu/A76/int-20191231-20161228/\n",
      "aws s3 sync int-20191231-20150114/ s3://dinosar/processing/uturuncu/A76/int-20191231-20150114/\n",
      "Moved files to s3://dinosar/processing/uturuncu/A76\n"
     ]
    }
   ],
   "source": [
    "# Move these to cloud storage\n",
    "# Push folder of text files to S3\n",
    "for i,p in enumerate(pairs):\n",
    "    intname = os.path.basename(p)\n",
    "    junk,master,slave=intname.split('-')\n",
    "    intdir = f'int-{master}-{slave}'\n",
    "    cmd = f'aws s3 sync {intdir}/ {bucket}/{intdir}/'\n",
    "    print(cmd)\n",
    "    subprocess.call(cmd, shell=True)\n",
    "\n",
    "print(f'Moved files to {bucket}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Launch AWS Batch (WARNING: can consume lots of AWS resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ····················\n"
     ]
    }
   ],
   "source": [
    "# Enter your NASA URS password to download SLCs\n",
    "nasauser = 'scottyhq'\n",
    "nasapass = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\n    \"jobName\": \"uturuncu-A76-test\",\\n    \"jobId\": \"b871173f-d102-4062-b7f9-1c352ad3e71b\"\\n}\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick whatever makes sense\n",
    "jobname = 'uturuncu-A76-test'\n",
    "\n",
    "# don't change these:\n",
    "demDir = 's3://dinosar/processing/uturuncu/dem'\n",
    "jobdef = 'uturuncu-array'\n",
    "jobqueue = 'uturuncu-queue'\n",
    "array_size = len(pairs)\n",
    "\n",
    "\n",
    "# NOTE: job-name, job-queue, and job-definition are JSON files that I've created for AWS Batch\n",
    "# The specify type of computers to use, etc\n",
    "cmd = f\"aws batch submit-job \\\n",
    "--job-name {jobname} \\\n",
    "--job-queue {jobqueue} \\\n",
    "--job-definition {jobdef} \\\n",
    "--array-properties size={array_size} \\\n",
    "--parameters 'S3_PAIRS={bucket}/{pairsFile},S3_DEM={demDir}' \\\n",
    "--container-overrides 'environment=[{{name=NASAUSER,value={nasauser}}},{{name=NASAPASS,value={nasapass}}}]' \\\n",
    "\"\n",
    "\n",
    "# warning: this prints your password as plain text, careful not to push to github\n",
    "#print(cmd)\n",
    "\n",
    "subprocess.check_output(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Wait for jobs to finish! \n",
    "\n",
    "* Merged/ results folder corresponding to s3://dinosar/processing/uturuncu/A76 found in s3://dinosar/results/uturuncu/A76\n",
    "\n",
    "* For now, monitor jobs here: https://us-west-2.console.aws.amazon.com/batch/home?region=us-west-2#/jobs/queue/arn:aws:batch:us-west-2:783380859522:job-queue~2Futuruncu-queue?state=PENDING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test AWS Batch workflow\n",
    "\n",
    "List of interferograms to process:\n",
    "A76 ints:\n",
    "* int_20191231_20180116\n",
    "* int_20191231_20161228\n",
    "* int_20191231_20150114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/scottyhq/dinosar.git@master\n",
      "  Cloning https://github.com/scottyhq/dinosar.git (to revision master) to /tmp/pip-req-build-6hg4lf4u\n",
      "  Running command git clone -q https://github.com/scottyhq/dinosar.git /tmp/pip-req-build-6hg4lf4u\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.22 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from dinosar==0.0.0) (2.23.0)\n",
      "Requirement already satisfied: pandas<2.0,>=1.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from dinosar==0.0.0) (1.0.3)\n",
      "Requirement already satisfied: shapely<2.0,>=1.6 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from dinosar==0.0.0) (1.7.0)\n",
      "Requirement already satisfied: lxml<5.0,>=4.4 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from dinosar==0.0.0) (4.5.0)\n",
      "Requirement already satisfied: geopandas<0.8,>=0.7 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from dinosar==0.0.0) (0.7.0)\n",
      "Requirement already satisfied: matplotlib<4.0,>=3.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from dinosar==0.0.0) (3.2.1)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.2 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from dinosar==0.0.0) (5.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests<3.0,>=2.22->dinosar==0.0.0) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests<3.0,>=2.22->dinosar==0.0.0) (1.25.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests<3.0,>=2.22->dinosar==0.0.0) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests<3.0,>=2.22->dinosar==0.0.0) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from pandas<2.0,>=1.0->dinosar==0.0.0) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from pandas<2.0,>=1.0->dinosar==0.0.0) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from pandas<2.0,>=1.0->dinosar==0.0.0) (1.18.1)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from geopandas<0.8,>=0.7->dinosar==0.0.0) (2.6.0)\n",
      "Requirement already satisfied: fiona in /srv/conda/envs/notebook/lib/python3.8/site-packages (from geopandas<0.8,>=0.7->dinosar==0.0.0) (1.8.13)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from matplotlib<4.0,>=3.1->dinosar==0.0.0) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from matplotlib<4.0,>=3.1->dinosar==0.0.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from matplotlib<4.0,>=3.1->dinosar==0.0.0) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas<2.0,>=1.0->dinosar==0.0.0) (1.14.0)\n",
      "Requirement already satisfied: attrs>=17 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from fiona->geopandas<0.8,>=0.7->dinosar==0.0.0) (19.3.0)\n",
      "Requirement already satisfied: click<8,>=4.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from fiona->geopandas<0.8,>=0.7->dinosar==0.0.0) (7.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from fiona->geopandas<0.8,>=0.7->dinosar==0.0.0) (0.5.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from fiona->geopandas<0.8,>=0.7->dinosar==0.0.0) (1.1.1)\n",
      "Requirement already satisfied: munch in /srv/conda/envs/notebook/lib/python3.8/site-packages (from fiona->geopandas<0.8,>=0.7->dinosar==0.0.0) (2.5.0)\n",
      "Building wheels for collected packages: dinosar\n",
      "  Building wheel for dinosar (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dinosar: filename=dinosar-0.0.0-py3-none-any.whl size=20268 sha256=642f01858025816f17cc23def9ad651cd339709b5dbdadb24ee270da213b699b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xvr1vc46/wheels/92/b0/87/750fc305aa2cac58744b55287e227c6fbf08fb234cb46ca2da\n",
      "Successfully built dinosar\n",
      "Installing collected packages: dinosar\n",
      "Successfully installed dinosar-0.0.0\n"
     ]
    }
   ],
   "source": [
    "# if dinosar library not in base environment uncomment below (run just once)\n",
    "!pip install --no-cache git+https://github.com/scottyhq/dinosar.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import dinosar\n",
    "import geopandas as gpd\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gfa = gpd.read_file('apmb.geojson')\n",
    "#gf = dinosar.archive.asf.load_inventory('query.geojson')\n",
    "#snwe = dinosar.archive.asf.ogr2snwe('apmb.geojson')\n",
    "#snwe\n",
    "\n",
    "# Smaller SNWE, also in template.yml\n",
    "relOrbit=76\n",
    "snwe = [-23.0, -21.5, -68, -66.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot S1 Footprints from S1 Archive (query.geojson)\n",
    "def refresh_inventory(snwe, orbit=relOrbit):\n",
    "    dinosar.archive.asf.query_asf(snwe, 'SA', orbit=relOrbit)\n",
    "    dinosar.archive.asf.query_asf(snwe, 'SB', orbit=relOrbit)\n",
    "    gf = dinosar.archive.asf.merge_inventories('query_SA.json', 'query_SB.json')\n",
    "    dinosar.archive.asf.save_inventory(gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying ASF Vertex for SA...\n",
      "https://api.daac.asf.alaska.edu/services/search/param?intersectsWith=POLYGON+%28%28-66.5+-23%2C+-66.5+-21.5%2C+-68+-21.5%2C+-68+-23%2C+-66.5+-23%29%29&platform=SA&processingLevel=SLC&beamMode=IW&output=json&relativeOrbit=76\n",
      "Querying ASF Vertex for SB...\n",
      "https://api.daac.asf.alaska.edu/services/search/param?intersectsWith=POLYGON+%28%28-66.5+-23%2C+-66.5+-21.5%2C+-68+-21.5%2C+-68+-23%2C+-66.5+-23%29%29&platform=SB&processingLevel=SLC&beamMode=IW&output=json&relativeOrbit=76\n",
      "Merging S1A and S1B inventories\n",
      "Saved inventory:  query.geojson\n"
     ]
    }
   ],
   "source": [
    "# Run if you want an up-to-date version of query.geojson\n",
    "refresh_inventory(snwe, relOrbit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) identify pairs to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use pandas to get list of interferograms programmatically, for now just list a few:\n",
    "pairs = ['int-20191231-20180116',\n",
    "         'int-20191231-20161228',\n",
    "         'int-20191231-20150114',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate processing directories and push to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp pairs.txt s3://dinosar/processing/uturuncu/A76-1/pairs.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an S3 bucket and move the list of pairs to S3\n",
    "bucket = 's3://dinosar/processing/uturuncu/A76-1'\n",
    "pairsFile = 'pairs.txt'\n",
    "\n",
    "paths = [bucket+'/'+x for x in pairs]\n",
    "with open(pairsFile, 'w') as f:\n",
    "    f.write('\\n'.join(paths))\n",
    "\n",
    "cmd = f'aws s3 cp {pairsFile} {bucket}/{pairsFile}'\n",
    "print(cmd)\n",
    "subprocess.call(cmd, shell=True)  # Uncomment to actually run command    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 's3://dinosar/processing/uturuncu/A76-1/int-20191231-20180116',\n",
       " 1: 's3://dinosar/processing/uturuncu/A76-1/int-20191231-20161228',\n",
       " 2: 's3://dinosar/processing/uturuncu/A76-1/int-20191231-20150114'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pairsFile) as f:\n",
    "    pairs = [line.rstrip() for line in f]\n",
    "    mapping = dict(enumerate(pairs))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prep_topsApp_local -i query.geojson -m 20191231 -p 76 -s 20180116 -t templateA76.yml\n",
      "1 prep_topsApp_local -i query.geojson -m 20191231 -p 76 -s 20161228 -t templateA76.yml\n",
      "2 prep_topsApp_local -i query.geojson -m 20191231 -p 76 -s 20150114 -t templateA76.yml\n"
     ]
    }
   ],
   "source": [
    "script = 'prep_topsApp_local'\n",
    "template = 'templateA76.yml'\n",
    "for i,p in enumerate(pairs):\n",
    "    intname = os.path.basename(p)\n",
    "    junk,master,slave=intname.split('-')\n",
    "    intdir = f'int-{master}-{slave}'\n",
    "    cmd = f'{script} -i query.geojson -m {master} -p {relOrbit} -s {slave} -t {template}'\n",
    "    print(i, cmd)\n",
    "    subprocess.call(cmd, shell=True) # Uncomment to actually run command  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 sync int-20191231-20180116/ s3://dinosar/processing/uturuncu/A76-1/int-20191231-20180116/\n",
      "aws s3 sync int-20191231-20161228/ s3://dinosar/processing/uturuncu/A76-1/int-20191231-20161228/\n",
      "aws s3 sync int-20191231-20150114/ s3://dinosar/processing/uturuncu/A76-1/int-20191231-20150114/\n",
      "Moved files to s3://dinosar/processing/uturuncu/A76-1\n"
     ]
    }
   ],
   "source": [
    "# Move these to cloud storage\n",
    "# Push folder of text files to S3\n",
    "for i,p in enumerate(pairs):\n",
    "    intname = os.path.basename(p)\n",
    "    junk,master,slave=intname.split('-')\n",
    "    intdir = f'int-{master}-{slave}'\n",
    "    cmd = f'aws s3 sync {intdir}/ {bucket}/{intdir}/'\n",
    "    print(cmd)\n",
    "    subprocess.call(cmd, shell=True)\n",
    "\n",
    "print(f'Moved files to {bucket}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Launch AWS Batch (WARNING: can consume lots of AWS resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ····················\n"
     ]
    }
   ],
   "source": [
    "# Enter your NASA URS password to download SLCs\n",
    "nasauser = 'scottyhq'\n",
    "nasapass = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\n    \"jobName\": \"uturuncu-A76-c5\",\\n    \"jobId\": \"08c34f2d-a363-458f-8f9b-8273a89548d7\"\\n}\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick whatever makes sense\n",
    "jobname = 'uturuncu-A76-c5'\n",
    "\n",
    "# don't change these:\n",
    "demDir = 's3://dinosar/processing/uturuncu/dem'\n",
    "jobdef = 'uturuncu-array-c5d'\n",
    "jobqueue = 'dinosar-c5d'\n",
    "array_size = len(pairs)\n",
    "\n",
    "\n",
    "# NOTE: job-name, job-queue, and job-definition are JSON files that I've created for AWS Batch\n",
    "# The specify type of computers to use, etc\n",
    "cmd = f\"aws batch submit-job \\\n",
    "--job-name {jobname} \\\n",
    "--job-queue {jobqueue} \\\n",
    "--job-definition {jobdef} \\\n",
    "--array-properties size={array_size} \\\n",
    "--parameters 'S3_PAIRS={bucket}/{pairsFile},S3_DEM={demDir}' \\\n",
    "--container-overrides 'environment=[{{name=NASAUSER,value={nasauser}}},{{name=NASAPASS,value={nasapass}}}]' \\\n",
    "\"\n",
    "\n",
    "# warning: this prints your password as plain text, careful not to push to github\n",
    "#print(cmd)\n",
    "\n",
    "subprocess.check_output(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Wait for jobs to finish! \n",
    "\n",
    "* Merged/ results folder corresponding to s3://dinosar/processing/uturuncu/A76 found in s3://dinosar/results/uturuncu/A76\n",
    "\n",
    "* For now, monitor jobs here: https://us-west-2.console.aws.amazon.com/batch/home?region=us-west-2#/jobs/queue/arn:aws:batch:us-west-2:783380859522:job-queue~2Futuruncu-queue?state=PENDING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
